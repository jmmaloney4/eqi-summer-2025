\documentclass[11pt,reqno]{amsart}

% -----------------------------------------------------------
% PACKAGES
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{tikz-cd} % CTAN: pgf
\usepackage{geometry}
\usepackage{braket}
\geometry{margin=1in}

% -----------------------------------------------------------
% THEOREM STYLES
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem*{note}{Note}

% -----------------------------------------------------------
% CUSTOM COMMANDS
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}

% -----------------------------------------------------------
% DOCUMENT START
\begin{document}

\title{Notes on \textit{Elements of Quantitative Investing} by Paleologo}
\author{Jack Maloney}
\email{jmmaloney4@gmail.com}
\date{\today}

\maketitle

\section{Prerequisites and Return Space}

\subsection{Probability Spaces and Measurable Functions}

\begin{definition}
	A \emph{probability space} is a triple $(\Omega, \mathcal{F}, P)$ where $\Omega$ is a set, $\mathcal{F}$ is a $\sigma$-algebra of subsets of $\Omega$, and $P: \mathcal{F} \to [0,1]$ is a probability measure with $P(\Omega) = 1$.
\end{definition}

The probability space is the fundamental object of probability theory. Many sets can be probability spaces, but one in particular is the \emph{physical measure} space, usually written as $(\Omega, \mathcal{F}, P)$.
This is the space of all possible states of the world, with a probability distribution that reflects our current knowledge \cite{clayton2023bernoulli}.
As you can imagine, there is not usually a great deal we can say about the physical measure space with any precision.
We can, however, make statements about certain random variables--functions from the physical measure space to the real numbers.
Random variables often model some obsevable quantity, such as the price of a stock, the weather, or the outcome of a coin flip.

\begin{definition}
	A \emph{random variable} is a measurable function $X: (\Omega, \mathcal{F}) \to (\mathbb{R}, \mathcal{B}(\mathbb{R}))$, where $\mathcal{B}(\mathbb{R})$ denotes the Borel $\sigma$-algebra on $\mathbb{R}$.

	Recall that a function $f: (\Omega, \mathcal{F}) \to (\mathbb{R}, \mathcal{B}(\mathbb{R}))$ is measurable if $f^{-1}(B) \in \mathcal{F}$ for all $B \in \mathcal{B}(\mathbb{R})$.
\end{definition}

\begin{example}
	Let \( X : \Omega \rightarrow \Set{1,0} \) be the random variable representing a particular coin toss. This means \(X\)  a map that assigns to each state of the universe \( \omega \in \Omega \) the value \(1\) if the coin lands heads and \(0\) if the coin lands tails.
	\begin{align*}
		\omega \mapsto \begin{cases}
			               1 & \text{if coin lands heads in state } \omega \\
			               0 & \text{if coin lands tails in state } \omega
		               \end{cases}
	\end{align*}
	For simplicity of modeling, we assume all states of the universe have a coin toss, that ends in either heads or tails, and so this function \(X\) is well-defined.
	Otherwise, we would have to extend the range to handle any exceptional cases.

	To assert that \(X\) is a random variable, we must claim that the set of heads \(X^{-1}(\Set{1})\) and the set of tails \(X^{-1}(\Set{0})\) are both measurable sets in the \(\sigma\)-algebra of the physical measure space, \(\mathcal{F}\).
\end{example}

What makes random variables useful is that they allow us to move from studying the physical measure space, to studying the real numbers under the distribution of the random variable.

\begin{definition}
	The \emph{distribution} of a random variable \(X\) is a measure defined on the real numbers, the pushforward of the physical measure \(P\) by \(X\),
	\begin{align*}
		X_{*}P (E) := P \left( X^{-1}(E) \right) \quad \text{for } E \in \mathcal{B}(\mathbb{R}).
	\end{align*}
\end{definition}

Most random variables encountered in practice have a distribution with the additional nice property of being represented by a density function.

\begin{definition}
	If a random variable is absolutely continuous with respect to Lebesgue measure, i.e. \(X_{*}P \ll \lambda\), then we say the random variable has a \emph{partial distribution function} or \emph{density function} (unique up to Lebesgue-null sets)
	\begin{align*}
		\mu_{X} = \frac{d X_{*}P}{d\lambda},
	\end{align*}
	the Radon-Nikodym derivative of the distribution with respect to Lebesgue measure.
\end{definition}

\subsection{Integration and Expectation}

\begin{definition}
	The \emph{expectation} (or \emph{mean}) of a random variable $X$ is the Lebesgue integral
	\begin{align}
		\mathbb{E}[X]
		 & := \int_\Omega X(\omega) \, dP(\omega) \quad \text{for } \omega \in \Omega \nonumber \\
		 & = \int_{\mathbb{R}} x \, dX_*P(dx).
	\end{align}
	provided the integral exists in the extended real line.
\end{definition}

% Todo:
sigma algebras represent information or knowledge of information.
- Relate to clayton2023bernoulli
- Give an explicit example of a filtration representing historical price information for a time series.

\begin{definition}
	Let $\mathcal{G} \subseteq \mathcal{F}$ be a sub-$\sigma$-algebra. The \emph{conditional expectation} of $X$ given $\mathcal{G}$, denoted $\mathbb{E}[X|\mathcal{G}]$, is the unique (up to almost sure equality) $\mathcal{G}$-measurable function satisfying
	\[
		\int_G \mathbb{E}[X|\mathcal{G}] \, dP = \int_G X \, dP, \quad \forall G \in \mathcal{G}.
	\]
\end{definition}

\begin{remark}
	In $L^2(\Omega, \mathcal{F}, P)$, $\mathbb{E}[X|\mathcal{G}]$ coincides with the orthogonal projection of $X$ onto the closed subspace of $\mathcal{G}$-measurable square-integrable random variables.
\end{remark}

\section{\texorpdfstring{$L^p$}{Lp} Spaces and Equivalence Classes}

\begin{definition}
	For $1 \leq p < \infty$, the space $L^p(\Omega, \mathcal{F}, P)$ consists of equivalence classes of measurable functions $X$ with finite $p$-th moment:
	\[
		\|X\|_p := \left( \int_\Omega |X|^p \, dP \right)^{1/p} < \infty.
	\]
\end{definition}

\begin{definition}
	Two random variables $X, Y$ are said to be \emph{equivalent} if $P(X \neq Y)=0$. Each element of $L^p$ is an equivalence class $[X]$ of almost surely equal functions.
\end{definition}

\begin{lemma}[Existence of Borel-Measurable Representatives]
	Let $X \in L^p(\Omega, \mathcal{F}, P)$. There exists a Borel-measurable representative $Y \in [X]$ that coincides with $X$ almost surely. However, no canonical representative exists in general.
\end{lemma}

\begin{note}
	In applications, representatives with additional regularity, such as continuity or cadlag paths, are often chosen to facilitate analysis and computations.
\end{note}

\begin{proposition}[Radon-Nikodym Derivative as Probability Density]
	Let $X$ be a random variable and let $P_X = X_*P$ denote its distribution. If $P_X \ll \lambda$ (the Lebesgue measure), then there exists a density function $f_X \in L^1(\mathbb{R})$ such that
	\[
		P_X(B) = \int_B f_X(x) \, dx, \quad \forall B \in \mathcal{B}(\mathbb{R}).
	\]
	This $f_X = \frac{dP_X}{d\lambda}$ is the \emph{probability density function} (pdf) of $X$.
\end{proposition}

% \section{Inner Product Structure and Covariance}
\subsection{Return Space and Covariance}

The most important random variables of study are the returns of financial assets, portfolios, and trading strategies.

\begin{definition}
	The space $L^2(\Omega, \mathcal{F}, P)$ is a Hilbert space with inner product
	\[
		\langle X, Y \rangle := \int_\Omega X Y \, dP.
	\]
\end{definition}

\begin{definition}
	For centered random variables (i.e., $\mathbb{E}[X]=0$), the \emph{covariance} is
	\[
		\operatorname{Cov}(X, Y) = \langle X, Y \rangle.
	\]
\end{definition}

\section{Moments and Generating Functions}

\begin{definition}
	The \emph{$n$-th moment} of a random variable $X$ is $\mathbb{E}[X^n]$, provided the expectation exists.
\end{definition}

\begin{theorem}[HÃ¶lder's Inequality]
	Let $1 \leq p, q \leq \infty$ with $\frac{1}{p} + \frac{1}{q} = 1$. Then
	\[
		|\mathbb{E}[XY]| \leq \|X\|_p \|Y\|_q.
	\]
\end{theorem}

\begin{definition}
	The \emph{moment generating function} (MGF) of $X$, if it exists in a neighborhood of zero, is
	\[
		M_X(t) := \mathbb{E}[e^{tX}].
	\]
\end{definition}

\section{Modes of Convergence}

\begin{definition}
	Let $\{X_n\}$ be a sequence of random variables. We distinguish several modes of convergence:
	\begin{enumerate}[label=(\roman*)]
		\item \emph{Almost sure convergence}: $X_n(\omega) \to X(\omega)$ for $P$-almost all $\omega$.
		\item \emph{Convergence in probability}: $\forall \varepsilon>0$, $P(|X_n - X| > \varepsilon) \to 0$.
		\item \emph{$L^p$ convergence}: $\|X_n - X\|_p \to 0$.
		\item \emph{Convergence in distribution}: $P_{X_n} \to P_X$ weakly.
	\end{enumerate}
\end{definition}

\begin{theorem}[Prokhorov's Theorem]
	A family of probability measures on a Polish space is tight if and only if it is relatively compact in the topology of weak convergence.
\end{theorem}

\begin{theorem}[Skorokhod's Representation Theorem]
	Let $P_{X_n} \to P_X$ weakly. Then there exist random variables $\{\tilde{X}_n\}$ and $\tilde{X}$ on a common probability space such that $\tilde{X}_n \xrightarrow{a.s.} \tilde{X}$ and $\tilde{X}_n$ has the same distribution as $X_n$ for each $n$.
\end{theorem}

\section{Functional Analytic Perspectives}

\begin{theorem}[Riesz Representation Theorem]
	Let $1 < p < \infty$. Every continuous linear functional on $L^p(\Omega, \mathcal{F}, P)$ is of the form
	\[
		\varphi(X) = \int_\Omega X Y \, dP
	\]
	for some $Y \in L^q(\Omega, \mathcal{F}, P)$ with $\frac{1}{p} + \frac{1}{q}=1$.
\end{theorem}

\begin{remark}
	This perspective frames the expectation as a continuous linear functional and highlights the duality between $L^p$ and $L^q$ spaces.
\end{remark}


% -----------------------------------------------------------
% REFERENCES
\begin{thebibliography}{9}

	\bibitem{ref1}
	Author Name, \emph{Title of Paper}, Journal Name, vol. XX, pp. 1--10, 20XX.

\end{thebibliography}

\end{document}
